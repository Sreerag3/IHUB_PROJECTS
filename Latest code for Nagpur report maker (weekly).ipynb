{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+/v5W6bms6zj/97QfsQJp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sreerag3/IHUB_PROJECTS/blob/main/Latest%20code%20for%20Nagpur%20report%20maker%20(weekly).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "dkLnnU3ezLvA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "data = pd.read_csv('/content/Trip Raw Report_November Jan 13.csv')\n",
        "df = data.copy()\n",
        "\n",
        "def custom_date_parser(date_str):\n",
        "    try:\n",
        "        return datetime.strptime(date_str, '%d-%m-%Y')\n",
        "    except ValueError:\n",
        "        return datetime.strptime(date_str,'%Y-%m-%d')\n",
        "\n",
        "df['startDate'] = df['startDate'].apply(custom_date_parser)\n",
        "dfs = []\n",
        "\n",
        "day_list = [(1, 8), (9, 16), (17, 24), (25, 30)]\n",
        "\n",
        "for day in day_list:\n",
        "    start_date = datetime(2023, 11, day[0])\n",
        "    end_date = datetime(2023, 11, day[1])\n",
        "    mask = (df['startDate'] >= start_date) & (df['startDate'] <= end_date)\n",
        "    filtered_df = df[mask]\n",
        "    filtered_df.reset_index(drop=True, inplace=True)\n",
        "    dfs.append(filtered_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the Excel file containing the list of faulty vehicle numbers\n",
        "faulty_vehicle_list = pd.read_excel('/content/week 1 nov faulty.xlsx')['VehicleNum'].tolist()\n",
        "\n",
        "# Remove rows when 'CAS' is 0 or 'VehicleNum' is in the faulty vehicle list\n",
        "data1 = dfs[0][~((dfs[0]['CAS'] == 0) | (dfs[0]['VehicleNum'].isin(faulty_vehicle_list)))]\n",
        "\n",
        "print(data1.shape)"
      ],
      "metadata": {
        "id": "lNYiaO_DOHr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the Excel file containing the list of faulty vehicle numbers\n",
        "faulty_vehicle_list = pd.read_excel('/content/week 2 nov faulty.xlsx')['VehicleNum'].tolist()\n",
        "\n",
        "# Remove rows when 'CAS' is 0 or 'VehicleNum' is in the faulty vehicle list\n",
        "data2 = dfs[1][~((dfs[1]['CAS'] == 0) | (dfs[1]['VehicleNum'].isin(faulty_vehicle_list)))]\n",
        "\n",
        "print(data2.shape)"
      ],
      "metadata": {
        "id": "D6MgKC5AOU_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the Excel file containing the list of faulty vehicle numbers\n",
        "faulty_vehicle_list = pd.read_excel('/content/week 3 nov faulty.xlsx')['VehicleNum'].tolist()\n",
        "\n",
        "# Remove rows when 'CAS' is 0 or 'VehicleNum' is in the faulty vehicle list\n",
        "data3 = dfs[2][~((dfs[2]['CAS'] == 0) | (dfs[2]['VehicleNum'].isin(faulty_vehicle_list)))]\n",
        "\n",
        "print(data3.shape)"
      ],
      "metadata": {
        "id": "gRPjIM3KOaVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the Excel file containing the list of faulty vehicle numbers\n",
        "faulty_vehicle_list = pd.read_excel('/content/week 4 nov faulty.xlsx')['VehicleNum'].tolist()\n",
        "\n",
        "# Remove rows when 'CAS' is 0 or 'VehicleNum' is in the faulty vehicle list\n",
        "data4 = dfs[3][~((dfs[3]['CAS'] == 0) | (dfs[3]['VehicleNum'].isin(faulty_vehicle_list)))]\n",
        "\n",
        "print(data4.shape)"
      ],
      "metadata": {
        "id": "9LqKLoNMOdTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df = pd.concat([data1,data2,data3,data4], axis=0, ignore_index=True)\n",
        "combined_df.to_excel(\"cleaned data.xlsx\")"
      ],
      "metadata": {
        "id": "gm67jHQ9SqhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_lists = ['distance', 'CAS', 'me_fcw_count', 'me_hmw_count', 'me_pcw_count', 'me_lldw_count', 'me_rldw_count']\n",
        "finaldata_ = combined_df.groupby(['groupName','driverName'])[count_lists].sum().reset_index()\n",
        "name_list = finaldata_['groupName'].unique()\n",
        "print(name_list)\n",
        "\n",
        "for g_value in name_list:\n",
        "\n",
        "  g_df = finaldata_[finaldata_['groupName'] == g_value]\n",
        "  f_name = f\"group_{g_value}.xlsx\"\n",
        "  g_df.to_excel(f_name, index=False)\n",
        "\n",
        "gp_df = data[data['groupName'] == 'Hansa-School-Bus-Fleet']\n",
        "\n",
        "count_lists = ['distance','CAS', 'me_fcw_count','me_hmw_count','me_pcw_count', 'me_lldw_count','me_rldw_count']\n",
        "\n",
        "gp_df = combined_df.groupby('VehicleNum')[count_lists].sum().reset_index()\n",
        "\n",
        "gp_df.to_excel(\"group_Hansa-School-Bus-Fleet.xlsx\")"
      ],
      "metadata": {
        "id": "AXnDRGvaLKp8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}