{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMis8F06bnWL8VS11g3b3Wl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sreerag3/IHUB_PROJECTS/blob/main/JAN%209%20CAS%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlqJyQyC95Vl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "data = pd.read_csv('/content/Trip Raw Report_November.csv')\n",
        "df = data.copy()\n",
        "\n",
        "def custom_date_parser(date_str):\n",
        "    try:\n",
        "        return datetime.strptime(date_str, '%d-%m-%Y')\n",
        "    except ValueError:\n",
        "        return datetime.strptime(date_str,'%Y-%m-%d')\n",
        "\n",
        "df['startDate'] = df['startDate'].apply(custom_date_parser)\n",
        "dfs = []\n",
        "\n",
        "day_list = [(1, 8), (9, 16), (17, 24), (25, 30)]\n",
        "\n",
        "for day in day_list:\n",
        "    start_date = datetime(2023, 11, day[0])\n",
        "    end_date = datetime(2023, 11, day[1])\n",
        "    mask = (df['startDate'] >= start_date) & (df['startDate'] <= end_date)\n",
        "    filtered_df = df[mask]\n",
        "    filtered_df.reset_index(drop=True, inplace=True)\n",
        "    dfs.append(filtered_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_lists = ['distance', 'CAS', 'me_fcw_count', 'me_hmw_count', 'me_pcw_count', 'me_lldw_count', 'me_rldw_count']\n",
        "\n",
        "# Group by 'groupName', 'VehicleNum', 'startDate', and 'driverName' in dfs[0] and sum the specified columns\n",
        "grouped1_data = dfs[0].groupby(['groupName', 'VehicleNum', 'startDate', 'driverName'])[count_lists].sum().reset_index()\n",
        "\n",
        "grouped1_data.to_excel('week1 Nov cas analysis.xlsx', index=False)"
      ],
      "metadata": {
        "id": "c9ad8cg998p_"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_lists = ['distance', 'CAS', 'me_fcw_count', 'me_hmw_count', 'me_pcw_count', 'me_lldw_count', 'me_rldw_count']\n",
        "\n",
        "# Group by 'groupName', 'VehicleNum', 'startDate', and 'driverName' in dfs[0] and sum the specified columns\n",
        "grouped2_data = dfs[1].groupby(['groupName', 'VehicleNum', 'startDate', 'driverName'])[count_lists].sum().reset_index()\n",
        "\n",
        "grouped2_data.to_excel('week2 Nov cas analysis.xlsx', index=False)"
      ],
      "metadata": {
        "id": "BI9tKR3TS5tv"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_lists = ['distance', 'CAS', 'me_fcw_count', 'me_hmw_count', 'me_pcw_count', 'me_lldw_count', 'me_rldw_count']\n",
        "\n",
        "# Group by 'groupName', 'VehicleNum', 'startDate', and 'driverName' in dfs[0] and sum the specified columns\n",
        "grouped3_data = dfs[1].groupby(['groupName', 'VehicleNum', 'startDate', 'driverName'])[count_lists].sum().reset_index()\n",
        "\n",
        "grouped3_data.to_excel('week3 Nov cas analysis.xlsx', index=False)"
      ],
      "metadata": {
        "id": "QBbt15uYTHWC"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_lists = ['distance', 'CAS', 'me_fcw_count', 'me_hmw_count', 'me_pcw_count', 'me_lldw_count', 'me_rldw_count']\n",
        "\n",
        "# Group by 'groupName', 'VehicleNum', 'startDate', and 'driverName' in dfs[0] and sum the specified columns\n",
        "grouped4_data = dfs[1].groupby(['groupName', 'VehicleNum', 'startDate', 'driverName'])[count_lists].sum().reset_index()\n",
        "\n",
        "grouped4_data.to_excel('week4 Nov cas analysis.xlsx', index=False)"
      ],
      "metadata": {
        "id": "GEW5ayCuTMMi"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# List of Excel file paths\n",
        "excel_file_paths = [\n",
        "    r'/content/Nov week 1 cas checking.xlsx',\n",
        "    r'/content/Nov week 2 cas checking.xlsx',\n",
        "    r'/content/Nov week 3 cas analysis.xlsx',\n",
        "    r'/content/Nov week 4 cas analysis.xlsx',\n",
        "    # Add more file paths as needed\n",
        "]\n",
        "\n",
        "# Read all Excel files into a list of pandas DataFrames\n",
        "dfs = [pd.read_excel(file_path) for file_path in excel_file_paths]\n",
        "\n",
        "# Perform the join operation by vertically concatenating the DataFrames\n",
        "merged_df = pd.concat(dfs, axis=0, ignore_index=True)\n",
        "\n",
        "# Save the result to a new Excel file\n",
        "merged_df.to_excel('combined file.xlsx', index=False)"
      ],
      "metadata": {
        "id": "b6b0gyTvcz28"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_lists = ['distance', 'CAS', 'me_fcw_count', 'me_hmw_count', 'me_pcw_count', 'me_lldw_count', 'me_rldw_count']\n",
        "finaldata_ = merged_df.groupby(['groupName','driverName'])[count_lists].sum().reset_index()\n",
        "print(finaldata_.shape)\n",
        "finaldata_.head()"
      ],
      "metadata": {
        "id": "wXdn6rUqe4gU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name_list = finaldata_['groupName'].unique()\n",
        "print(name_list)\n",
        "\n",
        "for g_value in name_list:\n",
        "\n",
        "  g_df = finaldata_[finaldata_['groupName'] == g_value]\n",
        "  f_name = f\"group_{g_value}.xlsx\"\n",
        "  g_df.to_excel(f_name, index=False)"
      ],
      "metadata": {
        "id": "Zxg1z2F5fQLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gp_df = merged_df[merged_df['groupName'] == 'Hansa-School-Bus-Fleet']\n",
        "\n",
        "count_lists = ['distance','CAS', 'me_fcw_count','me_hmw_count','me_pcw_count', 'me_lldw_count','me_rldw_count']\n",
        "\n",
        "gp_df = gp_df.groupby('VehicleNum')[count_lists].sum().reset_index()\n",
        "\n",
        "gp_df.head()"
      ],
      "metadata": {
        "id": "T5_1hliDfTL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gp_df.to_excel(\"group_Hansa-School-Bus-Fleet.xlsx\")"
      ],
      "metadata": {
        "id": "vS3J4UZzfVlm"
      },
      "execution_count": 51,
      "outputs": []
    }
  ]
}